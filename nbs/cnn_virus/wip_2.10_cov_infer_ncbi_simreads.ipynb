{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference using simulated CoV sequences from NCBI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we use simreads generated from NCBI CoV reference sequences to test inference, using the original pretrained CNN Virus model.\n",
    "\n",
    "This notebook works when run locally and also should run on Colab, as long as the file system is in line with the unified file ystem (see documentation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Imports and setup environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install and import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "`ecutilities` already installed\n",
      "`metagentools` already installed\n"
     ]
    }
   ],
   "source": [
    "# Install required custom packages if not installed yet.\n",
    "import importlib.util\n",
    "if not importlib.util.find_spec('ecutilities'):\n",
    "    print('installing package: `ecutilities`')\n",
    "    ! pip install -qqU ecutilities\n",
    "else:\n",
    "    print('`ecutilities` already installed')\n",
    "if not importlib.util.find_spec('metagentools'):\n",
    "    print('installing package: `metagentools')\n",
    "    ! pip install -qqU metagentools\n",
    "else:\n",
    "    print('`metagentools` already installed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Set autoreload mode\n",
      "Tensorflow version: 2.8.2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import all required packages\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "from ecutilities.core import files_in_tree\n",
    "from ecutilities.ipython import nb_setup\n",
    "from IPython.display import display, Markdown, HTML\n",
    "from pathlib import Path\n",
    "from pprint import pprint\n",
    "from tqdm.notebook import tqdm, trange\n",
    "\n",
    "# Setup the notebook for development\n",
    "nb_setup()\n",
    "\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' # or any {'0', '1', '2'}\n",
    "import tensorflow as tf\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.models import load_model\n",
    "print(f\"Tensorflow version: {tf.__version__}\\n\")\n",
    "\n",
    "from metagentools.cnn_virus.data import strings_to_tensors, create_infer_ds_from_fastq\n",
    "from metagentools.cnn_virus.data import FastaFileReader, FastqFileReader, AlnFileReader\n",
    "from metagentools.core import TextFileBaseReader, ProjectFileSystem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List all computing devices available on the machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Devices:\n",
      "  - CPU  /device:CPU:0                          \n",
      "  - GPU  /device:GPU:0  NVIDIA GeForce GTX 1050 \n"
     ]
    }
   ],
   "source": [
    "devices = device_lib.list_local_devices()\n",
    "print('\\nDevices:')\n",
    "for d in devices:\n",
    "    t = d.device_type\n",
    "    name = d.physical_device_desc\n",
    "    l = [item.split(':', 1) for item in name.split(', ')]\n",
    "    name_attr = dict([x for x in l if len(x)==2])\n",
    "    dev = name_attr.get('name', ' ')\n",
    "    print(f\"  - {t}  {d.name} {dev:25s}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Setup paths to files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Key folders and system information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running linux on local computer\n",
      "Device's home directory: /home/vtec\n",
      "Project file structure:\n",
      " - Root ........ /home/vtec/projects/bio/metagentools \n",
      " - Data Dir .... /home/vtec/projects/bio/metagentools/data \n",
      " - Notebooks ... /home/vtec/projects/bio/metagentools/nbs\n"
     ]
    }
   ],
   "source": [
    "pfs = ProjectFileSystem()\n",
    "pfs.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "ReadMe file for directory `data`:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Data structure for `metagentools`\n",
       "This directory includes all the data required for the project `metagentools`.\n",
       "\n",
       "```text\n",
       "data\n",
       " |--- CNN_Virus_data \n",
       " |--- ncbi           \n",
       " |--- ncov_data      \n",
       " |--- saved         \n",
       " |--- ....           \n",
       "     \n",
       "```\n",
       "#### Sub-directories\n",
       "- `CNN_Virus_data`: includes all the data related to the original CNN Virus paper, i.e. training data and validation data in a format that can be used by the CNN Virus code.\n",
       "- `ncbi`: includes data related to the use of CoV sequences from NCBI: reference sequences, simulated reads, inference datasets, inference results.\n",
       "- `ncov_data`: includes data related to the use of non Cov sequences from various sources: reference sequences, simulated reads, inference datasets, inference results.\n",
       "- `saved`: includes model saved parameters and preprocessing datasets.\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pfs.readme()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `p2model`: path to file with saved original pretrained model\n",
    "- `p2virus_labels` path to file with virus names and labels mapping for original model\n",
    "- `p2simreads`: path to folder where reads files are located (FASTQ and ALN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2model = pfs.data / 'saved/cnn_virus_original/pretrained_model.h5'\n",
    "assert p2model.is_file(), f\"No file found at {p2model.absolute()}\"\n",
    "\n",
    "p2virus_labels = pfs.data / 'CNN_Virus_data/virus_name_mapping'\n",
    "assert p2virus_labels.is_file(), f\"No file found at {p2virus_labels.absolute()}\"\n",
    "\n",
    "p2simreads = pfs.data / 'ncbi/simreads/'\n",
    "assert p2simreads.is_dir(), f\"No directory found at {p2simreads.absolute()}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "ReadMe file for directory `data/ncbi/simreads`:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### CoV simulated reads\n",
       "This directory includes a set of simulated read sequence files generated from NCBI CoV sequences using  ARC Illumina. \n",
       "\n",
       "```ascii\n",
       "this-directory\n",
       "    |\n",
       "    |--single_10seq_50bp\n",
       "    |    |--single_10seq_50bp.fq\n",
       "    |    |--single_10seq_50bp.alnEnd\n",
       "    |--single_100seq_50bp\n",
       "    |    |--single_100seq_50bp.fq\n",
       "    |    |--single_100seq_50bp.aln\n",
       "    |--single_100seq_150bp\n",
       "    |    |--single_100seq_150bp.fq\n",
       "    |    |--single_100seq_150bp.aln\n",
       "    |--paired_100seq_50bp\n",
       "    |    |--paired_100seq_50bp2.aln\n",
       "    |    |--paired_100seq_50bp1.aln\n",
       "    |    |--paired_100seq_50bp2.fq\n",
       "    |    |--paired_100seq_50bp1.fq\n",
       "    |-- ...\n",
       "```\n",
       "\n",
       "Each simread sub-directory is named as `<method>_<nb-seq>_<nb-bp>` where\"\n",
       "- `<method>` is either `single` or `paired` depending on the simulation method\n",
       "- `<nb-seq>` is the number of reference sequences used for simulation, and refers to the `fa` file used\n",
       "- `<nb-bp>` is the number of base pairs used to simulate reads\n",
       "\n",
       "\n",
       "Each sub-directory includes simreads files made using a simulation method and a specific number of reference sequences.\n",
       "- `xxx.fq` and `xxx.aln` files when method is `single`\n",
       "- `xxx1.fq`, `xxx2.fq`, `xxx1.aln` and `xxx2.aln` files when method is `paired`.\n",
       "\n",
       "Example:\n",
       "- `paired_10seq_50bp` means that the simreads were generated by using the `paired` method to simulate 50-bp reads, and using the `fa` file `cov_virus_sequences_010-seqs.fa`.\n",
       "- `single_100seq_50bp` means that the simreads were generated by using the `single` method to simulate 50-bp reads, and using the `fa` file `cov_virus_sequences_100-seqs.fa`. Note that this generated 20,660,104 reads !\n",
       "\n",
       "#### Simread file formats\n",
       "\n",
       "Simulated reads information is split between two files:\n",
       "- **FASTQ** (`.fq`) files providing the read sequences and their ASCII quality scores\n",
       "- **ALN** (`.aln`) files with alignment information\n",
       "\n",
       "##### FASTQ (`.fq`)\n",
       "FASTQ files generated by ART Illumina have the following structure (showing 5 reads), with 4 lines for each read:\n",
       "\n",
       "```ascii\n",
       "@2591237:ncbi:1-60400\n",
       "ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n",
       "+\n",
       "CCCBCGFGBGGGGGGGBGGGGGGGGG>GGG1G=/GGGGGGGGGGGGGGGG\n",
       "@2591237:ncbi:1-60399\n",
       "GATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n",
       "+\n",
       "BCBCCFGGGGGGGG1CGGGG<GGBGGGGGFGCGGGGGGDGGG/GG1GGGG\n",
       "@2591237:ncbi:1-60398\n",
       "ATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n",
       "+\n",
       "CCCCCGGGEGG1GGF1G/GGEGGGGGGGGGGGGFFGGGGGGGGGGDGGDG\n",
       "@2591237:ncbi:1-60397\n",
       "CGTAAAGTAGAGGCTGTATGGTAGCTAGCACAAATGCCAGCACCAATAGG\n",
       "+\n",
       "BCCCCGGGFGGGGGGFGGGGFGG1GGGGGGG>GG1GGGGGGGGGGE<GGG\n",
       "@2591237:ncbi:1-60396\n",
       "GGTATCGGGTATCTCCTGCATCAATGCAAGGTCTTACAAAGATAAATACT\n",
       "+\n",
       "CBCCCGGG@CGGGGGGGGGGGG=GFGGGGDGGGFG1GGGGGGGG@GGGGG\n",
       "```\n",
       "The following information can be parsed from the each read sequence in the FASTQ file:\n",
       "\n",
       "- Line 1: `readid`, a unique ID for the read, under for format `@readid` \n",
       "- Line 2: `readseq`, the sequence of the read\n",
       "- Line 3: a separator `+`\n",
       "- Line 4: `read_qscores`, the base quality scores encoded in ASCII \n",
       "\n",
       "Example:\n",
       "```\n",
       "@2591237:ncbi:1-60400\n",
       "ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n",
       "+\n",
       "CCCBCGFGBGGGGGGGBGGGGGGGGG>GGG1G=/GGGGGGGGGGGGGGGG\n",
       "```\n",
       "- `readid` = `2591237:ncbi:1-60400`\n",
       "- `readseq` = `ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG`, a 50 bp read\n",
       "- `read_qscores` = `CCCBCGFGBGGGGGGGBGGGGGGGGG>GGG1G=/GGGGGGGGGGGGGGGG`\n",
       "\n",
       "\n",
       "#### ALN (`.aln`) \n",
       "ALN files generated by ART Illumina consist of :\n",
       "- a header with the ART-Ilumina command used for the simulation (`@CM`) and info on each of the reference sequences used for the simulations (`@SQ`). Header always starts with `##ART_Illumina` and ends with `##Header End` :\n",
       "- the body with 3 lines for each read:\n",
       "    1. definition line with `readid`, \n",
       "        - reference sequence identification number `refseqid`, \n",
       "        - the position in the read in the reference sequence `aln_start_pos` \n",
       "        - the strand the read was taken from `ref_seq_strand`. `+` for coding strand and `-` for template strand\n",
       "    2. aligned reference sequence, that is the sequence segment in the original reference corresponding to the read\n",
       "    3. aligned read sequence, that is the simmulated read sequence, where each bp corresponds to the reference sequence bp in the same position.\n",
       "\n",
       "Example of a ALN file generated by ART Illumina (showing 5 reads):\n",
       "\n",
       "```ascii\n",
       "##ART_Illumina    read_length    50\n",
       "@CM    /bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/cov_data/cov_virus_sequences_ten.fa -ss HS25 -l 50 -f 100 -o /home/vtec/projects/bio/metagentools/data/cov_simreads/single_10seq_50bp/single_10seq_50bp -rs 1674660835\n",
       "@SQ    2591237:ncbi:1 [MK211378]    2591237    ncbi    1 [MK211378] 2591237    Coronavirus BtRs-BetaCoV/YN2018D    30213\n",
       "@SQ    11128:ncbi:2 [LC494191]    11128    ncbi    2 [LC494191] 11128    Bovine coronavirus    30942\n",
       "@SQ    31631:ncbi:3 [KY967361]    31631    ncbi    3 [KY967361] 31631    Human coronavirus OC43        30661\n",
       "@SQ    277944:ncbi:4 [LC654455]    277944    ncbi    4 [LC654455] 277944    Human coronavirus NL63    27516\n",
       "@SQ    11120:ncbi:5 [MN987231]    11120    ncbi    5 [MN987231] 11120    Infectious bronchitis virus    27617\n",
       "@SQ    28295:ncbi:6 [KU893866]    28295    ncbi    6 [KU893866] 28295    Porcine epidemic diarrhea virus    28043\n",
       "@SQ    28295:ncbi:7 [KJ645638]    28295    ncbi    7 [KJ645638] 28295    Porcine epidemic diarrhea virus    27998\n",
       "@SQ    28295:ncbi:8 [KJ645678]    28295    ncbi    8 [KJ645678] 28295    Porcine epidemic diarrhea virus    27998\n",
       "@SQ    28295:ncbi:9 [KR873434]    28295    ncbi    9 [KR873434] 28295    Porcine epidemic diarrhea virus    28038\n",
       "@SQ    1699095:ncbi:10 [KT368904]    1699095    ncbi    10 [KT368904] 1699095    Camel alphacoronavirus    27395\n",
       "##Header End\n",
       ">2591237:ncbi:1    2591237:ncbi:1-60400    14770    +\n",
       "ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n",
       "ACAACTCCTATTCGTAGTTGAAGTTGTTGACAAATACTTTGATTGTTACG\n",
       ">2591237:ncbi:1    2591237:ncbi:1-60399    17012    -\n",
       "GATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n",
       "GATCAATGTGGCATCTACAATACAGACAGCATGAAGCACCACCAAAGGAC\n",
       ">2591237:ncbi:1    2591237:ncbi:1-60398    9188    +\n",
       "ATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n",
       "ATCTACCAGTGGTAGATGGGTTCTTAATAATGAACATTATAGAGCTCTAC\n",
       ".....\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pfs.readme(dir_path=p2simreads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ncbi\n",
      "  |--simreads\n",
      "  |    |--readme.md (0)\n",
      "  |    |--paired_25seq_150bp\n",
      "  |    |    |--paired_25seq_150bp2.fq (1)\n",
      "  |    |    |--paired_25seq_150bp1.aln (2)\n",
      "  |    |    |--paired_25seq_150bp2.aln (3)\n",
      "  |    |    |--paired_25seq_150bp1.fq (4)\n",
      "  |    |--paired_100seq_150bp\n",
      "  |    |    |--paired_100seq_150bp1.aln (5)\n",
      "  |    |    |--paired_100seq_150bp2.aln (6)\n",
      "  |    |    |--paired_100seq_150bp1.fq (7)\n",
      "  |    |    |--paired_100seq_150bp2.fq (8)\n",
      "  |    |--paired_100seq_50bp\n",
      "  |    |    |--paired_100seq_50bp2.aln (9)\n",
      "  |    |    |--paired_100seq_50bp1.aln (10)\n",
      "  |    |    |--paired_100seq_50bp2.fq (11)\n",
      "  |    |    |--paired_100seq_50bp1.fq (12)\n",
      "  |    |--paired_10seq_150bp\n",
      "  |    |    |--paired_10seq_150bp1.aln (13)\n",
      "  |    |    |--paired_10seq_150bp2.fq (14)\n",
      "  |    |    |--paired_10seq_150bp2.aln (15)\n",
      "  |    |    |--paired_10seq_150bp1.fq (16)\n",
      "  |    |--paired_10seq_50bp\n",
      "  |    |    |--paired_10seq_50bp2.aln (17)\n",
      "  |    |    |--paired_10seq_50bp1.fq (18)\n",
      "  |    |    |--paired_10seq_50bp1.aln (19)\n",
      "  |    |    |--paired_10seq_50bp2.fq (20)\n",
      "  |    |--single_25seq_50bp\n",
      "  |    |    |--single_25seq_50bp.aln (21)\n",
      "  |    |    |--single_25seq_50bp.fq (22)\n",
      "  |    |--single_10seq_50bp\n",
      "  |    |    |--single_10seq_50bp.fq (23)\n",
      "  |    |    |--single_10seq_50bp.aln (24)\n",
      "  |    |--single_25seq_150bp\n",
      "  |    |    |--single_25seq_150bp.fq (25)\n",
      "  |    |    |--single_25seq_150bp.aln (26)\n",
      "  |    |--single_10seq_150bp\n",
      "  |    |    |--single_10seq_150bp.fq (27)\n",
      "  |    |    |--single_10seq_150bp.aln (28)\n",
      "  |    |--single_100seq_50bp\n",
      "  |    |    |--single_100seq_50bp.fq (29)\n",
      "  |    |    |--single_100seq_50bp.aln (30)\n",
      "  |    |--single_100seq_150bp\n",
      "  |    |    |--single_100seq_150bp.fq (31)\n",
      "  |    |    |--single_100seq_150bp.aln (32)\n",
      "  |    |--paired_25seq_50bp\n",
      "  |    |    |--paired_25seq_50bp1.fq (33)\n",
      "  |    |    |--paired_25seq_50bp2.aln (34)\n",
      "  |    |    |--paired_25seq_50bp2.fq (35)\n",
      "  |    |    |--paired_25seq_50bp1.aln (36)\n"
     ]
    }
   ],
   "source": [
    "files_in_tree(path=p2simreads);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this experiment, we will use the follwoing simreads:\n",
    "- 50 bp, single\n",
    "- from 10 reference sequences\n",
    "\n",
    "This means we will use the files in `data/ncbi/simreads/single_10seq_50bp`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/vtec/projects/bio/metagentools/data/ncbi/simreads/single_10seq_50bp')"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p2simreads = pfs.data / 'ncbi/simreads' / 'single_10seq_50bp'\n",
    "assert p2simreads.is_dir()\n",
    "p2simreads.absolute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " fq reads file:  single_10seq_50bp.fq\n",
      " aln reads file: single_10seq_50bp.aln\n"
     ]
    }
   ],
   "source": [
    "p2fastq = p2simreads / f\"{p2simreads.stem}.fq\"\n",
    "assert p2fastq.is_file()\n",
    "p2aln = p2simreads / f\"{p2simreads.stem}.aln\"\n",
    "assert p2aln.is_file()\n",
    "\n",
    "print(f\" fq reads file:  {p2fastq.name}\\n aln reads file: {p2aln.name}\")\n",
    "\n",
    "fastq = FastqFileReader(p2fastq)\n",
    "aln = AlnFileReader(p2aln)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Review data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ART Illumina command to generate the reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/art_illumina -i /home/vtec/projects/bio/metagentools/data/cov_data/cov_virus_sequences_ten.fa -ss HS25 -l 50 -f 100 -o /home/vtec/projects/bio/metagentools/data/cov_simreads/single_10seq_50bp/single_10seq_50bp -rs 1674660835\n"
     ]
    }
   ],
   "source": [
    "print(aln.header['command'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference Sequences:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coronavirus BtRs-BetaCoV/YN2018D  scientific name\n",
      "Bovine coronavirus  scientific name\n",
      "Human coronavirus OC43  scientific name\n",
      "Human coronavirus NL63  scientific name\n",
      "Infectious bronchitis virus  scientific name\n",
      "Porcine epidemic diarrhea virus  scientific name\n",
      "Porcine epidemic diarrhea virus  scientific name\n",
      "Porcine epidemic diarrhea virus  scientific name\n",
      "Porcine epidemic diarrhea virus  scientific name\n",
      "Camel alphacoronavirus  scientific name\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([v['species'] for v in aln.ref_sequences.values()]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Create inference dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model expect a dataset file in the following format:\n",
    "\n",
    "```text\n",
    "    AAAAAGATTTTGAGAGAGGTCGACCTGTCCTCCTAAAACGTTTACAAAAG\n",
    "    CATGTAACGCAGCTTAGTCCGATCGTGGCTATAATCCGTCTTTCGATTTG\n",
    "    AACAACATCTTGTTGATGATAACCGTCAAAGTGTTTTGGGTCTGGAGGGA\n",
    "    AGTACCTGGAGAGCGTTAAGAAACACAAACGGCTGGATGTAGTGCCGCGC\n",
    "    CCACGTCGATGAAGCTCCGACGAGAGTCGGCGCTGAGCCCGCGCACCTCC\n",
    "```\n",
    "\n",
    "Each line corresponds to a **read sequence**. During inference, the model will predict the **virus species code** and the **relative position** of the read in the full reference sequence.\n",
    "\n",
    "The mapping between code and virus specie name are in the file `virus_labels.csv`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a text dataset file from the simulated read output files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `create_infer_ds_from_fastq` takes reads from a `fastq` file and creates an inference dataset as a text file in the format expected by the model. \n",
    "\n",
    "The function returns the path to the inference dataset file, as well as a DataFrame with all refseq metadata. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Datasets are saved into `data/ds`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2datasets = pfs.data / 'ncbi/ds'\n",
    "assert p2datasets.is_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "ReadMe file for directory `data/ncbi/ds`:"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Inference and Training Datasets\n",
       "\n",
       "When using simread files (`fa` and `aln`) for inference, an inference dataset in a format required by the CNN Virus model must be build. In addition, metadata can be extracted to make it easier to analyse the result from different perspectives.\n",
       "\n",
       "This directory includes the generated inference datasets and metadata for each inference experiment.\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pfs.readme(dir_path=p2datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single_25seq_50bp_metadata.csv\n",
      "single_10seq_50bp_metadata.csv\n",
      "single_25seq_50bp_ds\n",
      "single_10seq_50bp_ds\n"
     ]
    }
   ],
   "source": [
    "print('\\n'.join([p.name for p in p2datasets.glob('*') if p.suffix not in ['.md']]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the dataset and the metadata file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "361ff6b18c3a42688b365037d822c21c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset with 571,980 reads\n"
     ]
    }
   ],
   "source": [
    "nsamples = None\n",
    "\n",
    "p2ds, p2meta, reads_info = create_infer_ds_from_fastq(\n",
    "    p2fastq=p2fastq, \n",
    "    output_dir=p2datasets,\n",
    "    overwrite_ds=True, \n",
    "    nsamples=nsamples\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Path to inference dataset file: /home/vtec/projects/bio/metagentools/data/ncbi/ds/single_10seq_50bp_ds\n",
      "Path to read metadata file:     /home/vtec/projects/bio/metagentools/data/ncbi/ds/single_10seq_50bp_metadata.csv\n"
     ]
    }
   ],
   "source": [
    "print(f\"Path to inference dataset file: {p2ds.absolute()}\")\n",
    "print(f\"Path to read metadata file:     {p2meta.absolute()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>read_ids</th>\n",
       "      <th>read_refseqs</th>\n",
       "      <th>read_start_pos</th>\n",
       "      <th>read_strand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2591237:ncbi:1-60400</td>\n",
       "      <td>2591237:ncbi:1</td>\n",
       "      <td>14770</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2591237:ncbi:1-60399</td>\n",
       "      <td>2591237:ncbi:1</td>\n",
       "      <td>17012</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2591237:ncbi:1-60398</td>\n",
       "      <td>2591237:ncbi:1</td>\n",
       "      <td>9188</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2591237:ncbi:1-60397</td>\n",
       "      <td>2591237:ncbi:1</td>\n",
       "      <td>6764</td>\n",
       "      <td>-</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2591237:ncbi:1-60396</td>\n",
       "      <td>2591237:ncbi:1</td>\n",
       "      <td>27357</td>\n",
       "      <td>+</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               read_ids    read_refseqs read_start_pos read_strand\n",
       "0  2591237:ncbi:1-60400  2591237:ncbi:1          14770           +\n",
       "1  2591237:ncbi:1-60399  2591237:ncbi:1          17012           -\n",
       "2  2591237:ncbi:1-60398  2591237:ncbi:1           9188           +\n",
       "3  2591237:ncbi:1-60397  2591237:ncbi:1           6764           -\n",
       "4  2591237:ncbi:1-60396  2591237:ncbi:1          27357           +"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reads_info.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the data loader for the model "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define batch size and create a first dataset accessing data from the dataset text file. Batch size can be adjusted depending on the memory available on the GPU. For reference, `bs = 4096` was used with a 4GB GPU. \n",
    "\n",
    "Then transform the text dataset into a tensor dataset by applying the `string_to_tensor` preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 4096\n",
    "\n",
    "text_ds = tf.data.TextLineDataset(p2ds).batch(bs)\n",
    "ds = text_ds.map(strings_to_tensors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The bases in the read sequences are encoded as a 5-dim one-hot-encoded vector, as the model expects.\n",
    "\n",
    "In this example, each 50bp read in converted into a tensor of shape [50,5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4096, 50, 5)\n",
      "tf.Tensor(\n",
      "[[1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0.]\n",
      " [0. 0. 0. 1. 0.]\n",
      " [1. 0. 0. 0. 0.]], shape=(10, 5), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "for batch, (y1b, y2b) in ds.take(1):\n",
    "    # show the shape of one batch\n",
    "    print(batch.shape)\n",
    "    # show the forst 10 bases, after one-hot-endoding\n",
    "    print(batch[0, :10, :])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load and review the pretrained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(p2model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)           [(None, 50, 5)]      0           []                               \n",
      "                                                                                                  \n",
      " conv1d_1 (Conv1D)              (None, 50, 512)      13312       ['input_1[0][0]']                \n",
      "                                                                                                  \n",
      " batch_normalization_1 (BatchNo  (None, 50, 512)     2048        ['conv1d_1[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_1 (MaxPooling1D)  (None, 25, 512)     0           ['batch_normalization_1[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_2 (Conv1D)              (None, 25, 512)      1311232     ['max_pooling1d_1[0][0]']        \n",
      "                                                                                                  \n",
      " batch_normalization_2 (BatchNo  (None, 25, 512)     2048        ['conv1d_2[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_2 (MaxPooling1D)  (None, 13, 512)     0           ['batch_normalization_2[0][0]']  \n",
      "                                                                                                  \n",
      " conv1d_3 (Conv1D)              (None, 13, 1024)     3671040     ['max_pooling1d_2[0][0]']        \n",
      "                                                                                                  \n",
      " conv1d_4 (Conv1D)              (None, 13, 1024)     7341056     ['conv1d_3[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_3 (BatchNo  (None, 13, 1024)    4096        ['conv1d_4[0][0]']               \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " max_pooling1d_3 (MaxPooling1D)  (None, 7, 1024)     0           ['batch_normalization_3[0][0]']  \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 7168)         0           ['max_pooling1d_3[0][0]']        \n",
      "                                                                                                  \n",
      " dense_1 (Dense)                (None, 1024)         7341056     ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " batch_normalization_4 (BatchNo  (None, 1024)        4096        ['dense_1[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " dropout_1 (Dropout)            (None, 1024)         0           ['batch_normalization_4[0][0]']  \n",
      "                                                                                                  \n",
      " output1 (Dense)                (None, 187)          191675      ['dropout_1[0][0]']              \n",
      "                                                                                                  \n",
      " concatenate_1 (Concatenate)    (None, 1211)         0           ['dropout_1[0][0]',              \n",
      "                                                                  'output1[0][0]']                \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 1024)         1241088     ['concatenate_1[0][0]']          \n",
      "                                                                                                  \n",
      " batch_normalization_5 (BatchNo  (None, 1024)        4096        ['dense_2[0][0]']                \n",
      " rmalization)                                                                                     \n",
      "                                                                                                  \n",
      " output2 (Dense)                (None, 10)           10250       ['batch_normalization_5[0][0]']  \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 21,137,093\n",
      "Trainable params: 21,128,901\n",
      "Non-trainable params: 8,192\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Present the inference dataset to the model and collect prediction.\n",
    "\n",
    "The model returns two sets of probabilities:\n",
    "- `prob_preds_species`: a vector of 187 values representing the probability that each of the 187 species are the correct ones, for each input read\n",
    "- `prob_preds_pos`: a vector of 10 values representing the probability that the read is from the corresponding segment of the original sequence (1 to 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3 µs, sys: 0 ns, total: 3 µs\n",
      "Wall time: 5.48 µs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "140/140 [==============================] - 133s 913ms/step\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "prob_preds_species, prob_preds_pos = model.predict(ds, verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((571980, 187), (571980, 10))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prob_preds_species.shape, prob_preds_pos.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To find the prediction, we pick the argmax probability, which gives us the index/code for the predicted virus species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([117, 117, 117, 117,  32,  89, 117, 117,  94, 117])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_preds = np.argmax(prob_preds_species, axis=1)\n",
    "class_preds.shape\n",
    "class_preds[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "117 is for `SARS` and 94 for `MERS`. We see that there are a few errors in prediction as all the reference sequences are either SARS or MERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Simple evaluation of the model for CoV"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Original model was trained with 187 different virus species."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original model is trained to detect 187 virus species, including 2 coronavirus species:\n",
      " - Middle_East_respiratory_syndrome-related_coronavirus    \t94\n",
      " - Severe_acute_respiratory_syndrome-related_coronavirus    \t117\n",
      "\n"
     ]
    }
   ],
   "source": [
    "p2virus_labels = pfs.data / 'CNN_Virus_data/virus_name_mapping'\n",
    "with open(p2virus_labels, 'r') as fp:\n",
    "    i, c = 0, 0\n",
    "    cov = []\n",
    "    while True:\n",
    "        line  = fp.readline()\n",
    "        if line == '': break\n",
    "        elif ('corona' in line) or ('mers' in line) : \n",
    "            c += 1\n",
    "            line = line.replace('\\t', '    \\t')\n",
    "            cov.append(f\" - {line}\")\n",
    "        i += 1\n",
    "print(f\"Original model is trained to detect {i} virus species, including {c} coronavirus species:\")\n",
    "print(''.join(cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our objective is to validate that the model detects either a MERS or a SARS species out of the reads: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- RefSeq 1: Coronavirus BtRs-BetaCoV/YN2018D  \n",
      "- RefSeq 2: Bovine coronavirus  \n",
      "- RefSeq 3: Human coronavirus OC43  \n",
      "- RefSeq 4: Human coronavirus NL63  \n",
      "- RefSeq 5: Infectious bronchitis virus  \n",
      "- RefSeq 6: Porcine epidemic diarrhea virus  \n",
      "- RefSeq 7: Porcine epidemic diarrhea virus  \n",
      "- RefSeq 8: Porcine epidemic diarrhea virus  \n",
      "- RefSeq 9: Porcine epidemic diarrhea virus  \n",
      "- RefSeq 10: Camel alphacoronavirus  \n"
     ]
    }
   ],
   "source": [
    "for i, v in enumerate(aln.ref_sequences.values()):\n",
    "    print(f\"- RefSeq {i+1}: {v['species'].replace('scientific name','')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "We create several test functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_cov(y_preds):\n",
    "    \"\"\"Return 1 if the corresponding prediction is a corona virus, 0 otherwise\"\"\"\n",
    "    return (y_preds == 94).astype(int) + (y_preds == 117).astype(int)\n",
    "\n",
    "def is_mers(y_preds):\n",
    "    \"\"\"Returns 1 if model prediction is MERS and 0 otherwise\n",
    "\n",
    "    Note: 94 is the code for Middle_East_respiratory_syndrome-related_coronavirus\"\"\"\n",
    "    return y_preds == 94\n",
    "\n",
    "def is_sars(y_preds):\n",
    "    \"\"\"Returns 1 if model prediction is SARS and 0 otherwise\n",
    "\n",
    "    Note: 117 is the virus code for Severe_acute_respiratory_syndrome-related_coronavirus \n",
    "    \"\"\"\n",
    "    return y_preds == 117\n",
    "\n",
    "def cov_acc(y_true, y_preds):\n",
    "    \"\"\"Evaluates the accuracy of the model assuming all evaluated reads are from corona virus sequences\"\"\"\n",
    "    return is_cov(y_preds).sum()/y_preds.shape[0]\n",
    "\n",
    "def mers_acc(y_true, y_preds):\n",
    "    \"\"\"Evaluates the accuracy of the model assuming all evaluated reads are from corona virus sequences\"\"\"\n",
    "    return is_mers(y_preds).sum()/y_preds.shape[0]\n",
    "\n",
    "def sars_acc(y_true, y_preds):\n",
    "    \"\"\"Evaluates the accuracy of the model assuming all evaluated reads are from corona virus sequences\"\"\"\n",
    "    return is_sars(y_preds).sum()/y_preds.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review all reads, broken down per reference sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b04a73c86a4421a80fc0a9e2692b815",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reference Sequence: Coronavirus BtRs-BetaCoV/YN2018D  scientific name:\n",
      "  Nbr reads: 60,400\n",
      "  Accuracy CoV:   0.733\n",
      "  Accuracy MERS:  0.014\n",
      "  Accuracy SARS:  0.719\n",
      "Reference Sequence: Bovine coronavirus  scientific name:\n",
      "  Nbr reads: 61,800\n",
      "  Accuracy CoV:   0.055\n",
      "  Accuracy MERS:  0.030\n",
      "  Accuracy SARS:  0.026\n",
      "Reference Sequence: Human coronavirus OC43  scientific name:\n",
      "  Nbr reads: 61,080\n",
      "  Accuracy CoV:   0.057\n",
      "  Accuracy MERS:  0.031\n",
      "  Accuracy SARS:  0.026\n",
      "Reference Sequence: Human coronavirus NL63  scientific name:\n",
      "  Nbr reads: 55,000\n",
      "  Accuracy CoV:   0.067\n",
      "  Accuracy MERS:  0.031\n",
      "  Accuracy SARS:  0.035\n",
      "Reference Sequence: Infectious bronchitis virus  scientific name:\n",
      "  Nbr reads: 55,200\n",
      "  Accuracy CoV:   0.065\n",
      "  Accuracy MERS:  0.032\n",
      "  Accuracy SARS:  0.034\n",
      "Reference Sequence: Porcine epidemic diarrhea virus  scientific name:\n",
      "  Nbr reads: 56,000\n",
      "  Accuracy CoV:   0.068\n",
      "  Accuracy MERS:  0.032\n",
      "  Accuracy SARS:  0.036\n",
      "Reference Sequence: Porcine epidemic diarrhea virus  scientific name:\n",
      "  Nbr reads: 55,900\n",
      "  Accuracy CoV:   0.069\n",
      "  Accuracy MERS:  0.033\n",
      "  Accuracy SARS:  0.036\n",
      "Reference Sequence: Porcine epidemic diarrhea virus  scientific name:\n",
      "  Nbr reads: 55,900\n",
      "  Accuracy CoV:   0.070\n",
      "  Accuracy MERS:  0.032\n",
      "  Accuracy SARS:  0.038\n",
      "Reference Sequence: Porcine epidemic diarrhea virus  scientific name:\n",
      "  Nbr reads: 56,000\n",
      "  Accuracy CoV:   0.068\n",
      "  Accuracy MERS:  0.032\n",
      "  Accuracy SARS:  0.036\n",
      "Reference Sequence: Camel alphacoronavirus  scientific name:\n",
      "  Nbr reads: 54,700\n",
      "  Accuracy CoV:   0.074\n",
      "  Accuracy MERS:  0.035\n",
      "  Accuracy SARS:  0.039\n"
     ]
    }
   ],
   "source": [
    "aln = AlnFileReader(p2fastq.parent / f\"{p2fastq.stem}.aln\")\n",
    "\n",
    "acc_per_refseq = {}\n",
    "for refseqid in tqdm(reads_info.read_refseqs.unique()):\n",
    "    mask = reads_info.read_refseqs == refseqid\n",
    "    acc = cov_acc(None, class_preds[mask])\n",
    "    aln_refseq_meta = aln.ref_sequences[refseqid]\n",
    "    print(f\"Reference Sequence: {aln_refseq_meta['species']}:\")\n",
    "    print(f\"  Nbr reads: {class_preds[mask].shape[0]:,d}\")\n",
    "    print(f\"  Accuracy CoV:   {acc:.3f}\")\n",
    "    print(f\"  Accuracy MERS:  {mers_acc(None, class_preds[mask]):.3f}\")\n",
    "    print(f\"  Accuracy SARS:  {sars_acc(None, class_preds[mask]):.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ecc87890d0e4d0288a4d03d4bcb66ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ref. Sequence: Coronavirus BtRs-BetaCoV/YN2018D:\n",
      "  Accuracy :............... 0.733\n",
      "  Acc. coding strand: ..... 0.733\n",
      "  Acc. template strand: ... 0.733\n",
      "  Nbr reads: 60,400, incl. 30,099 from coding strand and 30,301 from template strand\n",
      "\n",
      "Ref. Sequence: Bovine coronavirus:\n",
      "  Accuracy :............... 0.055\n",
      "  Acc. coding strand: ..... 0.058\n",
      "  Acc. template strand: ... 0.053\n",
      "  Nbr reads: 61,800, incl. 30,928 from coding strand and 30,872 from template strand\n",
      "\n",
      "Ref. Sequence: Human coronavirus OC43:\n",
      "  Accuracy :............... 0.057\n",
      "  Acc. coding strand: ..... 0.064\n",
      "  Acc. template strand: ... 0.051\n",
      "  Nbr reads: 61,080, incl. 30,565 from coding strand and 30,515 from template strand\n",
      "\n",
      "Ref. Sequence: Human coronavirus NL63:\n",
      "  Accuracy :............... 0.067\n",
      "  Acc. coding strand: ..... 0.062\n",
      "  Acc. template strand: ... 0.071\n",
      "  Nbr reads: 55,000, incl. 27,560 from coding strand and 27,440 from template strand\n",
      "\n",
      "Ref. Sequence: Infectious bronchitis virus:\n",
      "  Accuracy :............... 0.065\n",
      "  Acc. coding strand: ..... 0.068\n",
      "  Acc. template strand: ... 0.063\n",
      "  Nbr reads: 55,200, incl. 27,632 from coding strand and 27,568 from template strand\n",
      "\n",
      "Ref. Sequence: Porcine epidemic diarrhea virus:\n",
      "  Accuracy :............... 0.068\n",
      "  Acc. coding strand: ..... 0.063\n",
      "  Acc. template strand: ... 0.072\n",
      "  Nbr reads: 56,000, incl. 28,267 from coding strand and 27,733 from template strand\n",
      "\n",
      "Ref. Sequence: Porcine epidemic diarrhea virus:\n",
      "  Accuracy :............... 0.069\n",
      "  Acc. coding strand: ..... 0.065\n",
      "  Acc. template strand: ... 0.072\n",
      "  Nbr reads: 55,900, incl. 27,964 from coding strand and 27,936 from template strand\n",
      "\n",
      "Ref. Sequence: Porcine epidemic diarrhea virus:\n",
      "  Accuracy :............... 0.070\n",
      "  Acc. coding strand: ..... 0.068\n",
      "  Acc. template strand: ... 0.071\n",
      "  Nbr reads: 55,900, incl. 27,756 from coding strand and 28,144 from template strand\n",
      "\n",
      "Ref. Sequence: Porcine epidemic diarrhea virus:\n",
      "  Accuracy :............... 0.068\n",
      "  Acc. coding strand: ..... 0.063\n",
      "  Acc. template strand: ... 0.073\n",
      "  Nbr reads: 56,000, incl. 27,963 from coding strand and 28,037 from template strand\n",
      "\n",
      "Ref. Sequence: Camel alphacoronavirus:\n",
      "  Accuracy :............... 0.074\n",
      "  Acc. coding strand: ..... 0.070\n",
      "  Acc. template strand: ... 0.077\n",
      "  Nbr reads: 54,700, incl. 27,313 from coding strand and 27,387 from template strand\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for refseqid in tqdm(reads_info.read_refseqs.unique()):\n",
    "    mask_refseq = reads_info.read_refseqs == refseqid\n",
    "    mask_strand_coding = reads_info.read_strand == '+'\n",
    "    mask_strand_template = reads_info.read_strand == '-'\n",
    "    mask_coding = (mask_strand_coding.astype(int) * mask_refseq.astype(int)).astype(bool)\n",
    "    mask_template = (mask_strand_template.astype(int) * mask_refseq.astype(int)).astype(bool)\n",
    "\n",
    "    aln_refseq_meta = aln.ref_sequences[refseqid]\n",
    "    acc = cov_acc(None, class_preds[mask_refseq])\n",
    "    acc_coding = cov_acc(None, class_preds[mask_coding])\n",
    "    acc_template = cov_acc(None, class_preds[mask_template])\n",
    "       \n",
    "    print(f\"Ref. Sequence: {aln_refseq_meta['species'].replace('scientific name', '').strip()}:\")\n",
    "    print(f\"  Accuracy :............... {acc:.3f}\")\n",
    "    print(f\"  Acc. coding strand: ..... {acc_coding:.3f}\")\n",
    "    print(f\"  Acc. template strand: ... {acc_template:.3f}\")\n",
    "    print(f\"  Nbr reads: {class_preds[mask_refseq].shape[0]:,d}, incl. {mask_coding.sum():,d} from coding strand and {mask_template.sum():,d} from template strand\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# New Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## end of section"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
