{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|default_exp wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running locally\n"
     ]
    }
   ],
   "source": [
    "#|hide\n",
    "# from __future__ import annotations\n",
    "from fastcore.test import *\n",
    "from fastcore.utils import run\n",
    "from metagentorch.cnn_virus.utils import setup_nb\n",
    "from nbdev.showdoc import *\n",
    "from typing import List\n",
    "\n",
    "import nbdev\n",
    "\n",
    "ON_COLAB, p2dataroot, p2data = setup_nb(_dev=True)\n",
    "\n",
    "if ON_COLAB:\n",
    "    cmd = 'pip install -qqU wandb'\n",
    "    run(cmd)\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|export\n",
    "# Imports all dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "# import tensorflow as tf\n",
    "import wandb\n",
    "\n",
    "from datetime import datetime\n",
    "from pathlib import Path\n",
    "from typing import Callable, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#|hide\n",
    "# print(f\"Tensorflow version: {tf.__version__} - Expected 2.8.2\")\n",
    "# print(f\"WandB version: {wandb.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# wandb\n",
    "\n",
    "> Tracking projects experiments with **WandB**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once setup, **WandB** tracks datasets, models, training runs, evaluation runs across several experiments. The original documentation is [here](https://docs.wandb.ai/).\n",
    "\n",
    "Key concepts we use in this package: \n",
    "\n",
    "- `Run` (status, losses and other metadata logged during training or evaluation experiments).\n",
    "- `Artifact` (datasets, code (incl. notebooks), models, ...).\n",
    "    - Artifacts can refer to a single file or to a directory with multiple files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Steps:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Login to **`wandb`**: \n",
    "    - May require an API key, which is available at [https://wandb.ai/authorize](https://wandb.ai/authorize). To access the API key, must be logged in onto WandB.\n",
    "- Initialize a **`Run`** with desired parameters and metadata\n",
    "- Perform operations to be tracked (e.g. train model, load dataset as artifact, ...)\n",
    "- Finish the **`Run`**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def login_nb(\n",
    "    nb_file: str|Path   # name of the notebook (str) or path to the notebook (Path)\n",
    "    ):\n",
    "    \"\"\"First step to setup WandB from notebook. Logs in and logs passed notebook as source of code\"\"\"\n",
    "\n",
    "    # Validate nb_file\n",
    "    if nb_file is None:\n",
    "        raise TypeError('the file name of the current nb is required to allow code tracking')\n",
    "    if isinstance(nb_file, str):\n",
    "        if nb_file[-6:] != '.ipynb': nb_file = f\"{nb_file}.ipynb\"\n",
    "        nb_file = Path.cwd() / nb_file\n",
    "    elif not isinstance(nb_file, Path):\n",
    "        raise TypeError('nb_file must me a `str` or a `Path`')\n",
    "    \n",
    "    if not nb_file.is_file():\n",
    "        raise ValueError(f\"{nb_file.name} is not a file, please correct the file name\")\n",
    "\n",
    "    # Registers notebook as WandB code\n",
    "    os.environ['WANDB_NOTEBOOK_NAME'] = str(nb_file.absolute())\n",
    "    print(f\"Logging in from notebook: {os.environ['WANDB_NOTEBOOK_NAME']}\")\n",
    "\n",
    "    wandb.login(relogin=False)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To allow WandB to store the code used for the session, the **name or path of the notebook must be passed** as argument `nb_file`.\n",
    "\n",
    "Example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging in from notebook: /home/vtec/projects/bio/metagentools/nbs-dev/01_wandb.ipynb\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvtecftyw\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "login_nb('01_wandb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`login_nb` raises error in the following cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `nb_file` is not passed, the function raises a `TypeError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_fail(login_nb, kwargs={'nb_file':None}, contains='the file name of the current nb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If `nb_file` is not a string or a Path, the function raises a `TypeError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_fail(login_nb, kwargs={'nb_file':999}, contains='nb_file must me a `str` or a `Path`')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- There must exist a file `nb_file` or a `ValueError` is raised"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_fail(login_nb, kwargs={'nb_file':'fake_file_name'}, contains='is not a file, please correct the file name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "class WandbRun():\n",
    "    \"\"\"Manages a WandB run and all logged actions performed while run is active. Close run with .finish()\"\"\"\n",
    "    \n",
    "    def __init__(\n",
    "        self,\n",
    "        entity: str='',             # user or organization under which the run will be logged. Default: `metagenomics_sh` \n",
    "        project: str='',            # name of the WandB project under which the run will be logged \n",
    "        run_name: str='',           # unique name for the run,\n",
    "        job_type: str='',           # e.g.: `load_datasets`, `train_exp`, ... \n",
    "        notes: str='',              # any text description or additional information to store with the run \n",
    "        logs_dir: str|Path|None= None,   # default is project_root/wandb-logs if None, or uses the passed Path\n",
    "        testing: bool=False         # (optional) If True, will not create a run on WandB. Use for local testing\n",
    "        ) :\n",
    "        \"\"\"Validates metadata inputs and initialize the wandb run, unless testing is set to True\"\"\"\n",
    "        \n",
    "        # Validate inputs\n",
    "        for k,v in [key_val for key_val in locals().items() if key_val[0] not in ['self', 'notes', 'testing', 'logs_dir']]:\n",
    "            if v == '': raise ValueError(f\"{k} may not be an empty string. Please provide a value\")\n",
    "\n",
    "        for k,v in [key_val for key_val in locals().items() if key_val[0] not in ['self', 'testing', 'logs_dir']]:\n",
    "            if not isinstance(v, str): raise TypeError(f\"{k} must be a string, not a {type(v)}\")\n",
    "\n",
    "        self.entity = entity\n",
    "        self.project = project\n",
    "        self.run_name = run_name\n",
    "        self.job_type = job_type\n",
    "        self.notes = notes\n",
    "        \n",
    "        if logs_dir is None:\n",
    "            self.wandb_logs = self._get_wandb_logs_dir()\n",
    "        elif isinstance(logs_dir, str):\n",
    "            self.wandb_logs = Path(logs_dir)\n",
    "        elif isinstance(logs_dir, Path):\n",
    "            self.wandb_logs = logs_dir\n",
    "        else:\n",
    "            raise ValueError(f\"logs_dir must be None, a str or a Path, not a {type(logs_dir)}\")\n",
    "        \n",
    "        if not testing:\n",
    "            self.run = wandb.init(\n",
    "                entity=entity, \n",
    "                project=project, \n",
    "                name=run_name, \n",
    "                job_type=job_type, \n",
    "                notes=notes, \n",
    "                save_code=True,\n",
    "                dir= self.wandb_logs\n",
    "            )\n",
    "\n",
    "    def finish(self):\n",
    "        \"\"\"End the run\"\"\"\n",
    "        self.run.finish()\n",
    "    \n",
    "    @staticmethod\n",
    "    def _get_wandb_logs_dir():\n",
    "        cur_dir_parents = Path().absolute().parents\n",
    "        wandb_logs_dir = [p for p in cur_dir_parents if 'nbs' not in p.name][0] / 'wandb-logs'\n",
    "        if not wandb_logs_dir.is_dir():\n",
    "            raise ValueError(f\"Cannot find the wandb-logs directory. Please specify the correct path \")\n",
    "        return wandb_logs_dir\n",
    "        \n",
    "    def upload_dataset(\n",
    "        self, \n",
    "        ds_path: str,                 # path to the file or directory to load as dataset artifact \n",
    "        ds_name: str,                 # name for the dataset\n",
    "        ds_type: str,                 # type of dataset: e.g. raw_data, processed_data, ...\n",
    "        ds_descr: str,                # short description of the dataset\n",
    "        ds_metadata: dict,            # keys/values for metadata on the dataset, eg. nb_samples, ...\n",
    "        load_type:str = 'file',       # `file` to load a single file, `dir` to load all files in a directory\n",
    "        wait_completion: bool = False # when True, wait completion of the logging before returning artifact\n",
    "        ):\n",
    "        \"\"\"Load a dataset from a file as WandB artifact, with associated information and metadata\"\"\"\n",
    "        \n",
    "        # validate ds_path\n",
    "        if load_type not in ['file', 'dir']:\n",
    "            raise ValueError(f\"load_type must be 'file' or 'dir'\")\n",
    "        if load_type == 'file' and not Path(ds_path).is_file():\n",
    "            raise ValueError(f\"No file found as {ds_path}. Please check path or load type\")\n",
    "        if load_type == 'dir' and not Path(ds_path).is_dir():\n",
    "            raise ValueError(f\"No directory found as {ds_path}. Please check path or load type\")\n",
    "\n",
    "        artifact = wandb.Artifact(name=ds_name, type=ds_type, description=ds_descr, metadata=ds_metadata)\n",
    "\n",
    "        if load_type == 'file':\n",
    "            artifact.add_file(ds_path, ds_name)\n",
    "        if load_type == 'dir':\n",
    "            artifact.add_dir(ds_path, ds_name)\n",
    "        \n",
    "        self.run.log_artifact(artifact)\n",
    "        \n",
    "        print(f\"Dataset {ds_name} is being logged as artifact ...\")\n",
    "        \n",
    "        if wait_completion:\n",
    "            artifact.wait()\n",
    "            print(f\"Dataset {ds_name} logging completed\")\n",
    "            print(f\"Artifact state: {artifact.state}\")\n",
    "        \n",
    "        return artifact"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a Run instance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "WandbRun allows to define a set of metadata associated with the run, such as `entity`, `project`, `name`, `job_type` and additional `notes`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Example:\n",
    "\n",
    "- set the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entity = 'metagenomics_sh'\n",
    "project = 'coding-with-nbdev'\n",
    "run_name = 'nbdev-test'\n",
    "job_type = \"code_testing\"\n",
    "notes = 'any other information of interest for the future'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- create a `WandbRun` instance called `wandb_run`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvtecftyw\u001b[0m (\u001b[33mmetagenomics_sh\u001b[0m). Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.19.5 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.16.6"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/home/vtec/projects/bio/metagentools/wandb-logs/wandb/run-20250201_174624-e4wz0f2e</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/metagenomics_sh/coding-with-nbdev/runs/e4wz0f2e' target=\"_blank\">nbdev-test</a></strong> to <a href='https://wandb.ai/metagenomics_sh/coding-with-nbdev' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/metagenomics_sh/coding-with-nbdev' target=\"_blank\">https://wandb.ai/metagenomics_sh/coding-with-nbdev</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/metagenomics_sh/coding-with-nbdev/runs/e4wz0f2e' target=\"_blank\">https://wandb.ai/metagenomics_sh/coding-with-nbdev/runs/e4wz0f2e</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval: false\n",
    "wandb_run = WandbRun(\n",
    "    entity=entity, \n",
    "    project=project, \n",
    "    run_name=run_name, \n",
    "    job_type=job_type, \n",
    "    notes=notes\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WandbRun` instantiation raises an error in the following cases:\n",
    "\n",
    "- If one of `entity`, `project`, `run_name` or `job_type` is not passed, the function raises a `ValueError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_fail(WandbRun, kwargs={}, contains='entity may not be an empty string')\n",
    "test_fail(WandbRun, kwargs={'entity':entity}, contains='project may not be an empty string')\n",
    "test_fail(WandbRun, kwargs={'entity':entity, 'project':project}, contains='run_name may not be an empty string')\n",
    "test_fail(WandbRun, kwargs={'entity':entity, 'project':project, 'run_name':run_name}, contains='job_type may not be an empty string')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- If one of `entity`, `project`, `run_name`, `job_type` or `notes` is not a string, the function raises a `TypeError`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "test_fail(\n",
    "    WandbRun, \n",
    "    kwargs={'entity':9, 'project':project, 'run_name':run_name, 'job_type':job_type, 'notes':notes, 'testing':True}, \n",
    "    contains='entity must be a string'\n",
    "    )\n",
    "test_fail(\n",
    "    WandbRun, \n",
    "    kwargs={'entity':entity, 'project':9, 'run_name':run_name, 'job_type':job_type, 'notes':notes, 'testing':True}, \n",
    "    contains='project must be a string'\n",
    "    )\n",
    "test_fail(\n",
    "    WandbRun, \n",
    "    kwargs={'entity':entity, 'project':project, 'run_name':9, 'job_type':job_type, 'notes':notes, 'testing':True}, \n",
    "    contains='run_name must be a string'\n",
    "    )\n",
    "test_fail(\n",
    "    WandbRun, \n",
    "    kwargs={'entity':entity, 'project':project, 'run_name':run_name, 'job_type':9, 'notes':notes, 'testing':True}, \n",
    "    contains='job_type must be a string'\n",
    "    )\n",
    "test_fail(\n",
    "    WandbRun, \n",
    "    kwargs={'entity':entity, 'project':project, 'run_name':run_name, 'job_type':job_type, 'notes':9, 'testing':True}, \n",
    "    contains='notes must be a string'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "---\n",
       "\n",
       "[source](https://github.com/vtecftwy/metagentools/blob/main/metagentools/wandb.py#L106){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### WandbRun.upload_dataset\n",
       "\n",
       ">      WandbRun.upload_dataset (ds_path:str, ds_name:str, ds_type:str,\n",
       ">                               ds_descr:str, ds_metadata:dict,\n",
       ">                               load_type:str='file',\n",
       ">                               wait_completion:bool=False)\n",
       "\n",
       "*Load a dataset from a file as WandB artifact, with associated information and metadata*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| ds_path | str |  | path to the file or directory to load as dataset artifact |\n",
       "| ds_name | str |  | name for the dataset |\n",
       "| ds_type | str |  | type of dataset: e.g. raw_data, processed_data, ... |\n",
       "| ds_descr | str |  | short description of the dataset |\n",
       "| ds_metadata | dict |  | keys/values for metadata on the dataset, eg. nb_samples, ... |\n",
       "| load_type | str | file | `file` to load a single file, `dir` to load all files in a directory |\n",
       "| wait_completion | bool | False | when True, wait completion of the logging before returning artifact |"
      ],
      "text/plain": [
       "---\n",
       "\n",
       "[source](https://github.com/vtecftwy/metagentools/blob/main/metagentools/wandb.py#L106){target=\"_blank\" style=\"float:right; font-size:smaller\"}\n",
       "\n",
       "### WandbRun.upload_dataset\n",
       "\n",
       ">      WandbRun.upload_dataset (ds_path:str, ds_name:str, ds_type:str,\n",
       ">                               ds_descr:str, ds_metadata:dict,\n",
       ">                               load_type:str='file',\n",
       ">                               wait_completion:bool=False)\n",
       "\n",
       "*Load a dataset from a file as WandB artifact, with associated information and metadata*\n",
       "\n",
       "|    | **Type** | **Default** | **Details** |\n",
       "| -- | -------- | ----------- | ----------- |\n",
       "| ds_path | str |  | path to the file or directory to load as dataset artifact |\n",
       "| ds_name | str |  | name for the dataset |\n",
       "| ds_type | str |  | type of dataset: e.g. raw_data, processed_data, ... |\n",
       "| ds_descr | str |  | short description of the dataset |\n",
       "| ds_metadata | dict |  | keys/values for metadata on the dataset, eg. nb_samples, ... |\n",
       "| load_type | str | file | `file` to load a single file, `dir` to load all files in a directory |\n",
       "| wait_completion | bool | False | when True, wait completion of the logging before returning artifact |"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "show_doc(WandbRun.upload_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a dataset from a single file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2ds = Path('data_dev/ncbi/refsequences/cov/cov_virus_sequence_one.fa')\n",
    "assert p2ds.is_file()\n",
    "\n",
    "ds_fname = str(p2ds.absolute())\n",
    "ds_name = 'cov_one_sequence'\n",
    "ds_type = 'cov_sequences'\n",
    "ds_descr = 'one covid sequence fasta file'\n",
    "\n",
    "ds_metadata = {\n",
    "    'nb_sequences': 1,\n",
    "    'file type': 'fasta',\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cov_one_sequence is being logged as artifact ...\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "atx_one_file = wandb_run.upload_dataset(\n",
    "    ds_path=ds_fname,\n",
    "    ds_name=ds_name,\n",
    "    ds_type=ds_type,\n",
    "    ds_descr=ds_descr,\n",
    "    ds_metadata=ds_metadata,\n",
    "    load_type='file',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load a dataset with several files from a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p2ds_dir = Path('data_dev/ncbi/refsequences/cov/single_1seq_150bp')\n",
    "assert p2ds_dir.is_dir()\n",
    "\n",
    "ds_dirname = str(p2ds_dir.absolute())\n",
    "ds_name = 'cov_reads_single_1_sequence_150bp'\n",
    "ds_type = 'sim_reads'\n",
    "ds_descr = 'Simulated single reads of one cov sequence fq and aln files'\n",
    "\n",
    "ds_metadata = {\n",
    "    'nb_sequences': 1,\n",
    "    'sim_type': 'single',\n",
    "    'read_length': 150,\n",
    "    'fold': 100,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Adding directory to artifact (/home/vtec/projects/bio/metagentools/nbs-dev/data_dev/ncbi/refsequences/cov/single_1seq_150bp)... Done. 0.2s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset cov_reads_single_1_sequence_150bp is being logged as artifact ...\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "atx_multi_files = wandb_run.upload_dataset(\n",
    "    ds_path=ds_dirname,\n",
    "    ds_name=ds_name,\n",
    "    ds_type=ds_type,\n",
    "    ds_descr=ds_descr,\n",
    "    ds_metadata=ds_metadata,\n",
    "    load_type='dir',\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`WandbRun.upload_dataset` raises an error in the following cases:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ds_path` is a file and `load_type` is `dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#|eval: false\n",
    "# Passing a file but defining load_type as 'dir'\n",
    "ds_path = str(Path('data_dev/cov_virus_sequence_one.fa').absolute())\n",
    "ds_name = 'test_ds'\n",
    "ds_type = 'to_delete'\n",
    "ds_descr = 'ds used for testing'\n",
    "\n",
    "ds_metadata = {\n",
    "    'type': 'test'\n",
    "}\n",
    "\n",
    "test_fail(\n",
    "    wandb_run.upload_dataset, \n",
    "    kwargs={'load_type':'dir', 'ds_path':ds_path, 'ds_name':ds_name, 'ds_type':ds_type, 'ds_descr':ds_descr, 'ds_metadata':ds_metadata}, \n",
    "    contains='No directory found as'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `ds_path` is a directory and `load_type` is 'file`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#|eval: false\n",
    "# Passing a directory but defining load_type as 'file'\n",
    "ds_path = str(Path('data_dev/single_one_150bp').absolute())\n",
    "ds_name = 'test_ds'\n",
    "ds_type = 'to_delete'\n",
    "ds_descr = 'ds used for testing'\n",
    "\n",
    "ds_metadata = {\n",
    "    'type': 'test'\n",
    "}\n",
    "\n",
    "test_fail(\n",
    "    wandb_run.upload_dataset, \n",
    "    kwargs={'load_type':'file', 'ds_path':ds_path, 'ds_name':ds_name, 'ds_type':ds_type, 'ds_descr':ds_descr, 'ds_metadata':ds_metadata}, \n",
    "    contains='No file found as'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `load_type` has another value then `file` or `dir`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "#|eval: false\n",
    "# load_type neither 'file' nor 'dir'\n",
    "ds_path = str(Path('data_dev/reads_single_one_150bp').absolute())\n",
    "ds_name = 'test_ds'\n",
    "ds_type = 'to_delete'\n",
    "ds_descr = 'ds used for testing'\n",
    "\n",
    "ds_metadata = {\n",
    "    'type': 'test'\n",
    "}\n",
    "\n",
    "test_fail(\n",
    "    wandb_run.upload_dataset, \n",
    "    kwargs={'load_type':'wrong_type', 'ds_path':ds_path, 'ds_name':ds_name, 'ds_type':ds_type, 'ds_descr':ds_descr, 'ds_metadata':ds_metadata}, \n",
    "    contains=\"load_type must be 'file' or 'dir'\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Close a WandB run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "709317b0fdb644f5bce454c2b8d6f29a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(Label(value='13.231 MB of 13.231 MB uploaded\\r'), FloatProgress(value=1.0, max=1.0)))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">nbdev-test</strong> at: <a href='https://wandb.ai/metagenomics_sh/coding-with-nbdev/runs/e4wz0f2e' target=\"_blank\">https://wandb.ai/metagenomics_sh/coding-with-nbdev/runs/e4wz0f2e</a><br/> View project at: <a href='https://wandb.ai/metagenomics_sh/coding-with-nbdev' target=\"_blank\">https://wandb.ai/metagenomics_sh/coding-with-nbdev</a><br/>Synced 7 W&B file(s), 0 media file(s), 6 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>/home/vtec/projects/bio/metagentools/wandb-logs/wandb/run-20250201_174624-e4wz0f2e/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#|eval: false\n",
    "wandb_run.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def entity_projects(\n",
    "    entity: str # name of the entity from which the projects will be retrieved\n",
    "    ) -> wandb.apis.public.Projects : # Projects iterator\n",
    "    \"\"\"Returns all projects under 'entity', as an iterable collection\"\"\"\n",
    "    api = wandb.Api()\n",
    "    projects = api.projects(entity=entity)\n",
    "    return projects"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`entity_projects` inquires WandB to retrieve all the projects, and returns them as an iterable object.\n",
    "\n",
    "Each element in the iterator is a `wandb.Project` object. Each [`Project`](https://docs.wandb.ai/ref/python/public-api/project) object has the following attributes:\n",
    "\n",
    "- `_attrs`: dict of attributes associated with the project (`id`, `name`, `entityName`, `createdAt`). These attributes can be called directly as `object.id`, ...\n",
    "- `entity`\n",
    "- `name`: project name\n",
    "- `path`: as a list [entity, name]\n",
    "- `url`: the url to the project workspace ('https://wandb.ai/entity/project/workspace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pytorch-intro:\n",
      "  name:    pytorch-intro\n",
      "  entity   vtecftyw\n",
      "  path:    ['vtecftyw', 'pytorch-intro']\n",
      "\n",
      "  url:     https://wandb.ai/vtecftyw/pytorch-intro/workspace\n",
      "  id:      UHJvamVjdDp2MTpweXRvcmNoLWludHJvOnZ0ZWNmdHl3\n",
      "  created: 2024-12-12T09:04:33Z\n",
      "  _attrs:  {'id': 'UHJvamVjdDp2MTpweXRvcmNoLWludHJvOnZ0ZWNmdHl3', 'name': 'pytorch-intro', 'entityName': 'vtecftyw', 'createdAt': '2024-12-12T09:04:33Z', 'isBenchmark': False}\n",
      "\n",
      "basic-intro:\n",
      "  name:    basic-intro\n",
      "  entity   vtecftyw\n",
      "  path:    ['vtecftyw', 'basic-intro']\n",
      "\n",
      "  url:     https://wandb.ai/vtecftyw/basic-intro/workspace\n",
      "  id:      UHJvamVjdDp2MTpiYXNpYy1pbnRybzp2dGVjZnR5dw==\n",
      "  created: 2024-12-12T08:54:34Z\n",
      "  _attrs:  {'id': 'UHJvamVjdDp2MTpiYXNpYy1pbnRybzp2dGVjZnR5dw==', 'name': 'basic-intro', 'entityName': 'vtecftyw', 'createdAt': '2024-12-12T08:54:34Z', 'isBenchmark': False}\n",
      "\n",
      "tut_artifacts:\n",
      "  name:    tut_artifacts\n",
      "  entity   vtecftyw\n",
      "  path:    ['vtecftyw', 'tut_artifacts']\n",
      "\n",
      "  url:     https://wandb.ai/vtecftyw/tut_artifacts/workspace\n",
      "  id:      UHJvamVjdDp2MTp0dXRfYXJ0aWZhY3RzOnZ0ZWNmdHl3\n",
      "  created: 2022-09-30T04:39:35Z\n",
      "  _attrs:  {'id': 'UHJvamVjdDp2MTp0dXRfYXJ0aWZhY3RzOnZ0ZWNmdHl3', 'name': 'tut_artifacts', 'entityName': 'vtecftyw', 'createdAt': '2022-09-30T04:39:35Z', 'isBenchmark': False}\n",
      "\n",
      "metagenomics:\n",
      "  name:    metagenomics\n",
      "  entity   vtecftyw\n",
      "  path:    ['vtecftyw', 'metagenomics']\n",
      "\n",
      "  url:     https://wandb.ai/vtecftyw/metagenomics/workspace\n",
      "  id:      UHJvamVjdDp2MTptZXRhZ2Vub21pY3M6dnRlY2Z0eXc=\n",
      "  created: 2022-09-09T10:39:00Z\n",
      "  _attrs:  {'id': 'UHJvamVjdDp2MTptZXRhZ2Vub21pY3M6dnRlY2Z0eXc=', 'name': 'metagenomics', 'entityName': 'vtecftyw', 'createdAt': '2022-09-09T10:39:00Z', 'isBenchmark': False}\n",
      "\n",
      "wand-hello-world-fastai:\n",
      "  name:    wand-hello-world-fastai\n",
      "  entity   vtecftyw\n",
      "  path:    ['vtecftyw', 'wand-hello-world-fastai']\n",
      "\n",
      "  url:     https://wandb.ai/vtecftyw/wand-hello-world-fastai/workspace\n",
      "  id:      UHJvamVjdDp2MTp3YW5kLWhlbGxvLXdvcmxkLWZhc3RhaTp2dGVjZnR5dw==\n",
      "  created: 2022-06-14T15:45:17Z\n",
      "  _attrs:  {'id': 'UHJvamVjdDp2MTp3YW5kLWhlbGxvLXdvcmxkLWZhc3RhaTp2dGVjZnR5dw==', 'name': 'wand-hello-world-fastai', 'entityName': 'vtecftyw', 'createdAt': '2022-06-14T15:45:17Z', 'isBenchmark': False}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "projs = entity_projects(entity='vtecftyw')\n",
    "\n",
    "for p in projs:\n",
    "    print(f\"{p.name}:\")\n",
    "    print('  name:   ', p.name)\n",
    "    print('  entity  ', p.entity)\n",
    "    print('  path:   ', p.path)\n",
    "    print()\n",
    "    print('  url:    ', p.url)\n",
    "    print('  id:     ', p.id)\n",
    "    print('  created:', p.createdAt)\n",
    "    print('  _attrs: ', p._attrs)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def get_project(\n",
    "    entity: str,        # name of the entity from which the project will be retrieved \n",
    "    project_name:str,   # name of the project to retrieve\n",
    "    ) -> wandb.apis.public.Project : # Project object\n",
    "    \"\"\"Returns project object defined by entity and project name\"\"\"\n",
    "    api = wandb.Api()\n",
    "    return api.from_path(f\"{entity}/{project_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'wandb.apis.public.projects.Project'>\n",
      "vtecftyw \n",
      " tut_artifacts \n",
      " ['vtecftyw', 'tut_artifacts'] \n",
      " https://wandb.ai/vtecftyw/tut_artifacts/workspace\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "p = get_project('vtecftyw', 'tut_artifacts')\n",
    "\n",
    "print(type(p))\n",
    "\n",
    "print(p.entity,'\\n', p.name,'\\n', p.path,'\\n', p.url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def print_entity_project_list(entity):\n",
    "    \"\"\"Print the name and url of all projects in entity\"\"\"\n",
    "    projects = entity_projects(entity)\n",
    "    print(f\"List of projects under entity <{entity}>\")\n",
    "    for i, p in enumerate(projects):\n",
    "        print(f\" {i:2d}. {p.name:30s} (url: {p.url})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List of projects under entity <vtecftyw>\n",
      "  0. pytorch-intro                  (url: https://wandb.ai/vtecftyw/pytorch-intro/workspace)\n",
      "  1. basic-intro                    (url: https://wandb.ai/vtecftyw/basic-intro/workspace)\n",
      "  2. tut_artifacts                  (url: https://wandb.ai/vtecftyw/tut_artifacts/workspace)\n",
      "  3. metagenomics                   (url: https://wandb.ai/vtecftyw/metagenomics/workspace)\n",
      "  4. wand-hello-world-fastai        (url: https://wandb.ai/vtecftyw/wand-hello-world-fastai/workspace)\n"
     ]
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "print_entity_project_list('vtecftyw')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def project_artifacts(\n",
    "    entity: str,                     # name of the entity from which to retrieve the artifacts \n",
    "    project_name: str,               # name of the project from which to retrieve the artifacts \n",
    "    by_alias: str='latest',          # name of the alias to filter by\n",
    "    by_type: str=None,               # name of the artifact type to filter by (optional)\n",
    "    by_version: str=None             # version to filter by (optional)\n",
    "    ) -> Tuple[pd.DataFrame, list]:  # df w/ all artifacts and related info; list of artifact types in the project\n",
    "    \"\"\"Returns all artifacts in project, w/ key info, filtered by alias, types and version + list of artifact types\"\"\"\n",
    "    api = wandb.Api()\n",
    "    project = api.from_path(f\"{entity}/{project_name}\")\n",
    "    atx_types = project.artifacts_types()\n",
    "    runs = api.runs(path=f\"{entity}/{project_name}\")\n",
    "\n",
    "    # validate by_type parameter\n",
    "    if by_type is not None and by_type not in [t.name for t in atx_types]:\n",
    "        raise ValueError(f\"{by_type} is not an artifact type in {entity}/{project_name}\")\n",
    "\n",
    "    # create a df where each row corresponds to one artifact logged during one run in this project\n",
    "    # some artifact may be duplicated when linked to more than one run. Those duplicate need to be filtered out\n",
    "    cols = 'atx_name atx_type atx_id atx_state atx_version atx_aliases file_count created updated'.split(' ')\n",
    "    artifacts_df = pd.DataFrame(columns=cols)\n",
    "    \n",
    "    for r in runs:\n",
    "        for atx in r.logged_artifacts():\n",
    "            metadata = [atx.name, atx.type, atx.id, atx.state, atx.version, atx.aliases, atx.file_count, atx.created_at, atx.updated_at]\n",
    "            row = pd.DataFrame({k:v for k, v in zip(cols, metadata)})\n",
    "            artifacts_df = pd.concat((artifacts_df, row), axis=0, ignore_index=True)\n",
    "    artifacts_df = artifacts_df.loc[~artifacts_df.duplicated(subset=['atx_id'], keep='first'), :]\n",
    "\n",
    "    cols2show = 'atx_name atx_version atx_type atx_aliases file_count created updated atx_id'.split(' ')\n",
    "    # filtering by passed alias and type:\n",
    "    #   if by_xxx is not None:    filter is a boolean vector\n",
    "    #   if by_xxx is None:        filter is an array of 'True'\n",
    "    nbr_rows = artifacts_df.shape[0]\n",
    "    alias_filter = artifacts_df.atx_aliases==by_alias if by_alias is not None else np.ones(shape=(nbr_rows,), dtype=bool)\n",
    "    type_filter = artifacts_df.atx_type==by_type if by_type is not None else np.ones(shape=(nbr_rows,), dtype=bool)\n",
    "    version_filter = artifacts_df.atx_version==by_version if by_version is not None else np.ones(shape=(nbr_rows,), dtype=bool)\n",
    "\n",
    "    row_filter = alias_filter * type_filter * version_filter\n",
    "\n",
    "    latest = artifacts_df.loc[row_filter, cols2show].sort_values(by='created').reset_index(drop=True)\n",
    "    return latest, [t.name for t in atx_types]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`project_artifacts` returns:\n",
    "\n",
    "- a DataFrame including all the artifacts available under the project (`entity/project_name`)\n",
    "- a list of all artifact types in the projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['code', 'cov_sequences', 'sim_reads', 'job']"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "atx_df, atx_type_list = project_artifacts(\n",
    "    entity='metagenomics_sh', \n",
    "    project_name='coding-with-nbdev'\n",
    "    )\n",
    "\n",
    "atx_type_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atx_name</th>\n",
       "      <th>atx_version</th>\n",
       "      <th>atx_type</th>\n",
       "      <th>atx_aliases</th>\n",
       "      <th>file_count</th>\n",
       "      <th>created</th>\n",
       "      <th>updated</th>\n",
       "      <th>atx_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>source-coding-with-nbdev-_home_vtec_projects_b...</td>\n",
       "      <td>v0</td>\n",
       "      <td>code</td>\n",
       "      <td>latest</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-01T09:46:40Z</td>\n",
       "      <td>2025-02-01T09:46:43Z</td>\n",
       "      <td>QXJ0aWZhY3Q6MTQ4MjA0MzE4Ng==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>cov_one_sequence:v0</td>\n",
       "      <td>v0</td>\n",
       "      <td>cov_sequences</td>\n",
       "      <td>latest</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-01T09:50:13Z</td>\n",
       "      <td>2025-02-01T09:50:15Z</td>\n",
       "      <td>QXJ0aWZhY3Q6MTQ4MjA0NjkyNQ==</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cov_reads_single_1_sequence_150bp:v0</td>\n",
       "      <td>v0</td>\n",
       "      <td>sim_reads</td>\n",
       "      <td>latest</td>\n",
       "      <td>2</td>\n",
       "      <td>2025-02-01T09:52:45Z</td>\n",
       "      <td>2025-02-01T10:02:12Z</td>\n",
       "      <td>QXJ0aWZhY3Q6MTQ4MjA0OTY3MA==</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            atx_name atx_version  \\\n",
       "0  source-coding-with-nbdev-_home_vtec_projects_b...          v0   \n",
       "1                                cov_one_sequence:v0          v0   \n",
       "2               cov_reads_single_1_sequence_150bp:v0          v0   \n",
       "\n",
       "        atx_type atx_aliases file_count               created  \\\n",
       "0           code      latest          1  2025-02-01T09:46:40Z   \n",
       "1  cov_sequences      latest          1  2025-02-01T09:50:13Z   \n",
       "2      sim_reads      latest          2  2025-02-01T09:52:45Z   \n",
       "\n",
       "                updated                        atx_id  \n",
       "0  2025-02-01T09:46:43Z  QXJ0aWZhY3Q6MTQ4MjA0MzE4Ng==  \n",
       "1  2025-02-01T09:50:15Z  QXJ0aWZhY3Q6MTQ4MjA0NjkyNQ==  \n",
       "2  2025-02-01T10:02:12Z  QXJ0aWZhY3Q6MTQ4MjA0OTY3MA==  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "atx_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of artifacts can be filtered, for instance, by artifact type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>atx_name</th>\n",
       "      <th>atx_version</th>\n",
       "      <th>atx_type</th>\n",
       "      <th>atx_aliases</th>\n",
       "      <th>file_count</th>\n",
       "      <th>created</th>\n",
       "      <th>updated</th>\n",
       "      <th>atx_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cov_one_sequence:v0</td>\n",
       "      <td>v0</td>\n",
       "      <td>cov_sequences</td>\n",
       "      <td>latest</td>\n",
       "      <td>1</td>\n",
       "      <td>2025-02-01T09:50:13Z</td>\n",
       "      <td>2025-02-01T09:50:15Z</td>\n",
       "      <td>QXJ0aWZhY3Q6MTQ4MjA0NjkyNQ==</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              atx_name atx_version       atx_type atx_aliases file_count  \\\n",
       "0  cov_one_sequence:v0          v0  cov_sequences      latest          1   \n",
       "\n",
       "                created               updated                        atx_id  \n",
       "0  2025-02-01T09:50:13Z  2025-02-01T09:50:15Z  QXJ0aWZhY3Q6MTQ4MjA0NjkyNQ==  "
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "atx_df, atx_type_list = project_artifacts(\n",
    "    entity='metagenomics_sh', \n",
    "    project_name='coding-with-nbdev',\n",
    "    by_type='cov_sequences'\n",
    "    )\n",
    "\n",
    "atx_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def run_name_exists(\n",
    "    run_name: str,      # name of the run to check \n",
    "    entity: str,        # name of the entity from which to retrieve the artifacts \n",
    "    project_name: str,  # name of the project from which to retrieve the artifacts \n",
    "    ) -> bool:          # True if a run exists with the name run_name, False otherwise\n",
    "    \"\"\"Check whether a run with name `run_name` already exists in `entity/project_name`\"\"\"\n",
    "    api = wandb.Api()\n",
    "    runs = api.runs(path=f\"{entity}/{project_name}\")\n",
    "    run_matches = [run_name == r.name for r in runs]\n",
    "    return any(run_matches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "run_name_exists(\n",
    "    run_name='nbdev-test', \n",
    "    entity='metagenomics_sh', \n",
    "    project_name='coding-with-nbdev'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#|eval: false\n",
    "\n",
    "run_name_exists(\n",
    "    run_name='train_1M', \n",
    "    entity='metagenomics_sh', \n",
    "    project_name='coding-with-nbdev'\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export\n",
    "def unique_run_name(\n",
    "    name_seed:str     # Run name to which a timestamp will be added\n",
    "    ):\n",
    "    \"\"\"Create a unique run name by adding a timestamp to the passed seed\"\"\"\n",
    "    timestamp = datetime.now().strftime('%y%m%d-%H%M')\n",
    "    return f\"{name_seed}-{timestamp}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this_is_a_run_name-250201-1816'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unique_run_name('this_is_a_run_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "def validate_config(\n",
    "    config\n",
    "    ):\n",
    "    \"\"\"Returns config dictionary where missing required keys are replaced into with default values\"\"\"\n",
    "    default_config = {\n",
    "        'architecture': 'cnn-virus-original',\n",
    "        'dataset': 'Dataset.map(string_to_tensor) v2',\n",
    "        'batch_size': 1024,\n",
    "        'learning_rate': 1e-3,\n",
    "        'epochs': 5,\n",
    "        'ds_cache': False,\n",
    "        'ds_prefetch': True,\n",
    "    }\n",
    "\n",
    "    if config is None: config = {}\n",
    "\n",
    "    for k, v in default_config.items():\n",
    "        config[k] = config.get(k, default_config[k])\n",
    "    \n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "\n",
    "# def train_with_wandb(\n",
    "#     entity: str, project_name: str, run_name_seed: str, \n",
    "#     train_ds_at_name: str, val_ds_at_name: str, \n",
    "#     model_at_name: str = None, build_model: Callable = None,\n",
    "#     config: dict = None \n",
    "#     ):\n",
    "#     \"\"\"Starts a new wandb run and performs a training sequence using datasets and (optional) saved model.\n",
    "    \n",
    "#     The function perform each of these steps:\n",
    "#         1. validate the config\n",
    "#         2. starts a new wandb run using the run_name_seed and the config dictionary\n",
    "#         3. downloads train and val raw text datasets and transforms them with the transform function\n",
    "#         4. load the selected saved model or creates new model, and compile it\n",
    "#         5. train the model, using wandb to track and save intermediate models\n",
    "#         6. finish the run\n",
    "\n",
    "#     Parameters\n",
    "#     ----------\n",
    "#     entity : str\n",
    "#         name of the WandB user or organization to use to create the new run\n",
    "#     project_name : str\n",
    "#         name of the project to use to create the new run. \n",
    "#     run_name_seed : str\n",
    "#         name to give to the new run\n",
    "#         the run display name will be this string followed by a timestamp\n",
    "#     train_ds_at_name : str\n",
    "#         name of the WandB Artifact with the train dataset.\n",
    "#         the name should not include any `:vn` version number\n",
    "#     val_ds_at_name : str\n",
    "#         name of the WandB Artifact with the validation dataset.\n",
    "#         the name should not include any `:vn` version number\n",
    "#     config : dict\n",
    "#         dictionary where key-value pairs represent all the metadata to store with the run\n",
    "#         the key-value pairs below are required and will be set as the default values if not present:\n",
    "#             'architecture' (default: 'cnn-virus-original')\n",
    "#             'dataset': (default: 'Dataset.map(string_to_tensor) v2')\n",
    "#             'n_train_samples': (default: 0) (retrieved from artifact metadata if available)\n",
    "#             'n_val_samples': (default: 0)   (retrieved from artifact metadata if available)\n",
    "#             'batch_size': (default: 1024)\n",
    "#             'learning_rate': (default: 1e-3)\n",
    "#             'epochs': (default: 5)\n",
    "#             'ds_cache': (default: False)\n",
    "#             'ds_prefetch': (default: True)\n",
    "#     model_at_name : str, default=None\n",
    "#         name of the WandB Artifact with the saved moded to use.\n",
    "#         the name should not include any `:vn` version number\n",
    "#         when `None`, a new model is created\n",
    "#     build_model : Callable,\n",
    "#         function to build an empty architecture\n",
    "\n",
    "#     \"\"\"\n",
    "#     run_name = unique_run_name(run_name_seed)\n",
    "\n",
    "#     # 1. validate configuration\n",
    "#     config = validate_config(config)\n",
    "\n",
    "#     # Retrieve n_samples from dataset artifacts metadata and save in config\n",
    "#     train_ds_at_path = f\"{entity}/{project_name}/{train_ds_at_name}:latest\"\n",
    "#     val_ds_at_path =   f\"{entity}/{project_name}/{val_ds_at_name}:latest\"\n",
    "#     api = wandb.Api()\n",
    "#     train_at = api.artifact(train_ds_at_path)\n",
    "#     val_at = api.artifact(val_ds_at_path)\n",
    "#     config['n_train_samples'] = train_at.metadata.get('n_samples', 0)\n",
    "#     config['n_val_samples'] = val_at.metadata.get('n_samples', 0)\n",
    "\n",
    "#     # 2. start a new run\n",
    "#     run = wandb.init(\n",
    "#         entity=entity, \n",
    "#         project=project_name, \n",
    "#         name=run_name, job_type=\"train-exp\", \n",
    "#         config=config, \n",
    "#         save_code=True\n",
    "#         )\n",
    "#     cfg = wandb.config\n",
    "\n",
    "#     # 3a. download train and val raw data files\n",
    "\n",
    "#     train_ds_at = run.use_artifact(train_ds_at_path, type='raw_data')\n",
    "#     train_ds_dir = train_ds_at.download()\n",
    "#     train_ds_file = list(Path(train_ds_dir).iterdir())[0]\n",
    "\n",
    "#     val_ds_at = run.use_artifact(val_ds_at_path, type='raw_data')\n",
    "#     val_ds_dir = val_ds_at.download()\n",
    "#     val_ds_file = list(Path(val_ds_dir).iterdir())[0]\n",
    "\n",
    "#     print(f\"Build Datasets from files {train_ds_file.name} and {val_ds_file.name}\")\n",
    "\n",
    "#     # 3.b create Datasets for train and val\n",
    "#     text_train_ds = tf.data.TextLineDataset(\n",
    "#         train_ds_file,\n",
    "#         compression_type='',\n",
    "#         name='text_train_ds'\n",
    "#     ).batch(cfg['batch_size'])\n",
    "\n",
    "#     text_val_ds = tf.data.TextLineDataset(\n",
    "#         val_ds_file,\n",
    "#         compression_type='',\n",
    "#         name='text_val_ds'\n",
    "#     ).batch(cfg['batch_size'])\n",
    "\n",
    "#     if config['ds_cache'] and config['ds_prefetch']:\n",
    "#         train_ds = text_train_ds.map(strings_to_tensors).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#         val_ds = text_val_ds.map(strings_to_tensors).cache().prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "#     elif not config['ds_cache'] and config['ds_prefetch']:\n",
    "#         train_ds = text_train_ds.map(strings_to_tensors).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "#         val_ds = text_val_ds.map(strings_to_tensors).prefetch(buffer_size=tf.data.AUTOTUNE)\n",
    "\n",
    "#     else:\n",
    "#         train_ds = text_train_ds.map(strings_to_tensors)\n",
    "#         val_ds = text_val_ds.map(strings_to_tensors)\n",
    "\n",
    "#     print(f\"dataset built with cache:{config['ds_cache']}, prefetch:{config['ds_prefetch']}.\")\n",
    "\n",
    "#     # create model using passed build function or loaded artifact, and compile it\n",
    "#     if model_at_name is None:\n",
    "#         if build_model is not None and callable(build_model):\n",
    "#             print('Creating a new model')\n",
    "#             model = build_cnn_virus_original()\n",
    "#         else:\n",
    "#             raise ValueError(f\"Require 'build_model' to be a callable to create a new model\")\n",
    "#     else:\n",
    "#         print(f\"Downloading and using latest version of model {model_at_name}\")\n",
    "#         model_at_path = f\"{project_name}/{model_at_name}:latest\"\n",
    "#         model_at = run.use_artifact(model_at_path, type='model')\n",
    "#         model_at_dir = model_at.download()\n",
    "#         model = tf.keras.models.load_model(Path(model_at_dir).resolve())\n",
    "\n",
    "#     optim = Adam(learning_rate=wandb.config.learning_rate)\n",
    "#     model.compile(\n",
    "#         optimizer=optim,\n",
    "#         loss=[CategoricalCrossentropy(name='l1'), CategoricalCrossentropy(name='l2')],\n",
    "#         metrics=['acc']\n",
    "#     )\n",
    "    \n",
    "#     # train model\n",
    "#     wb = WandbCallback(\n",
    "#         monitor=cfg['metric_to_monitor'], \n",
    "#         save_model=True, \n",
    "#         log_weigths=True\n",
    "#         )\n",
    "\n",
    "#     res = model.fit(\n",
    "#         train_ds,\n",
    "#         epochs=wandb.config.epochs,\n",
    "#         validation_data=val_ds,\n",
    "#         verbose=1,\n",
    "#         callbacks=[wb]\n",
    "#         )\n",
    "\n",
    "#     run.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Technical Notes for development with `nbdev`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Resolve problem with `nbdev_export()` for this notebook**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using `nbdev.nbdev_export()` in this notebook, the code exported seems to be old code. In particular, the dependency import section in cell is exported as:\n",
    "```python\n",
    "# %% ../nbs-dev/wandb/run-20221123_121523-2z5ycjrb/tmp/code/01_wandb.ipynb 2\n",
    "# Imports all dependencies\n",
    "\n",
    "import configparser\n",
    "import numpy as np\n",
    "import psutil\n",
    "import os\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hint is in the first line: \n",
    "\n",
    "**`# %% ../nbs-dev/wandb/run-20221123_121523-2z5ycjrb/tmp/code/01_wandb.ipynb 2`**\n",
    "\n",
    "It shows that the notebook used for exporting is not **`/nbs-dev/01_wandb.ipynb`** as it should be. This is because the WandB package creates a local directory `/nbs-dev/wandb/` where it keeps local logs and artifacts.\n",
    "\n",
    "The solution is to move the directory where WandB stores local logs outside `nbs-dev`, which can be done with the `dir` argument in `wandb.Run()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Illustrating by reproducing the functions from nbdev and a few dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nbdev.config import get_config\n",
    "from fastcore.xtras import globtastic\n",
    "from fastcore.meta import delegates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nbdev.doclinks.py\n",
    "\n",
    "# line 105\n",
    "@delegates(globtastic)\n",
    "def nbglob(path=None, skip_folder_re = '^[_.]', file_glob='*.ipynb', skip_file_re='^[_.]', key='nbs_path', as_path=False, **kwargs):\n",
    "    \"Find all files in a directory matching an extension given a config key.\"\n",
    "    path = Path(path or get_config()[key])\n",
    "    recursive=get_config().recursive\n",
    "    res = globtastic(path, file_glob=file_glob, skip_folder_re=skip_folder_re,\n",
    "                     skip_file_re=skip_file_re, recursive=recursive, **kwargs)\n",
    "    return res.map(Path) if as_path else res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# line 131 MODIFIED\n",
    "def modified_nbdev_export(\n",
    "    path:str=None, # Path or filename\n",
    "    **kwargs):\n",
    "    \"Export notebooks in `path` to Python modules\"\n",
    "    if os.environ.get('IN_TEST',0): return\n",
    "    files = nbglob(path=path, as_path=True, **kwargs).sorted('name')\n",
    "#     for f in files: nb_export(f)\n",
    "    for f in files: print(f)\n",
    "#     add_init(get_config().lib_path)\n",
    "#     _build_modidx()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before the change: \n",
    "```python\n",
    "modified_nbdev_export()\n",
    "```\n",
    "\n",
    "```ascii\n",
    "/home/vtec/projects/bio/metagentools/nbs-dev/00_core.ipynb\n",
    "/home/vtec/projects/bio/metagentools/nbs-dev/01_wandb.ipynb\n",
    "/home/vtec/projects/bio/metagentools/nbs-dev/wandb/run-20221122_182641-1eafsab9/tmp/code/01_wandb.ipynb\n",
    "/home/vtec/projects/bio/metagentools/nbs-dev/wandb/run-20221122_180513-1vgzoryt/tmp/code/01_wandb.ipynb\n",
    "/home/vtec/projects/bio/metagentools/nbs-dev/wandb/run-20221123_121523-2z5ycjrb/tmp/code/01_wandb.ipynb\n",
    "/home/vtec/projects/bio/metagentools/nbs-dev/index.ipynb\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After the change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/vtec/projects/bio/metagentools/nbs-dev/00_core.ipynb\n",
      "/home/vtec/projects/bio/metagentools/nbs-dev/01_wandb.ipynb\n",
      "/home/vtec/projects/bio/metagentools/nbs-dev/02_art.ipynb\n",
      "/home/vtec/projects/bio/metagentools/nbs-dev/03_bio.ipynb\n",
      "/home/vtec/projects/bio/metagentools/nbs-dev/03_cnn_virus_architecture.ipynb\n",
      "/home/vtec/projects/bio/metagentools/nbs-dev/03_cnn_virus_data.ipynb\n",
      "/home/vtec/projects/bio/metagentools/nbs-dev/03_cnn_virus_utils.ipynb\n",
      "/home/vtec/projects/bio/metagentools/nbs-dev/index.ipynb\n"
     ]
    }
   ],
   "source": [
    "modified_nbdev_export()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "26b205197a934fdeabb71e65ac11acba": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "514ad0bfcabf4df580a9a872af814af9": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "55646397fc9349d3af9e98b1f2b26f5d": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "70f6be4247664b708b662c34e7abe3ee": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7179c6cc207941648c348b1bf10cb87f": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "LabelModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "LabelModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "LabelView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_70f6be4247664b708b662c34e7abe3ee",
      "placeholder": "",
      "style": "IPY_MODEL_bdde467d943148ce9bb6355fd7582a5c",
      "value": "0.078 MB of 0.078 MB uploaded (0.020 MB deduped)\r"
     }
    },
    "7849f255e99b4853bdba7f8badf1054a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "VBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "VBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "VBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_7179c6cc207941648c348b1bf10cb87f",
       "IPY_MODEL_e0819a1ddcc64c08a748a2fd88350f09"
      ],
      "layout": "IPY_MODEL_26b205197a934fdeabb71e65ac11acba"
     }
    },
    "bdde467d943148ce9bb6355fd7582a5c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e0819a1ddcc64c08a748a2fd88350f09": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_55646397fc9349d3af9e98b1f2b26f5d",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_514ad0bfcabf4df580a9a872af814af9",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
